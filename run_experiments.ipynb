{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Distribution Shift in the AI Job Market\n",
                "\n",
                "This notebook demonstrates how ML models trained on historical AI job market data experience significant performance degradation when deployed on future data."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "from config import MODELS_DIR, OUTPUTS_DIR, FIGURES_DIR\n",
                "from data_processing import load_and_prepare_data, FeaturePreprocessor, get_temporal_splits, validate_no_leakage\n",
                "from model import BaselineModel, train_baseline\n",
                "from drift_detection import DriftDetector\n",
                "from evaluation import calculate_all_metrics, MonthlyEvaluator, RollingWindowRetrainer, StrategyComparison\n",
                "\n",
                "print(\"âœ“ Imports complete\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = load_and_prepare_data()\n",
                "print(f\"Dataset shape: {df.shape}\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Temporal Split"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_df, monthly_windows = get_temporal_splits(df)\n",
                "validate_no_leakage(train_df, monthly_windows)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Preprocess Features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "preprocessor = FeaturePreprocessor()\n",
                "preprocessor.fit(train_df)\n",
                "X_train, y_train = preprocessor.transform(train_df)\n",
                "\n",
                "print(f\"Features: {X_train.shape}\")\n",
                "print(f\"Target distribution:\", pd.Series(y_train).value_counts().sort_index().to_dict())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Train Baseline Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
                "OUTPUTS_DIR.mkdir(parents=True, exist_ok=True)\n",
                "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "model = train_baseline(X_train, y_train, preprocessor.feature_columns)\n",
                "\n",
                "y_train_pred = model.predict(X_train)\n",
                "y_train_proba = model.predict_proba(X_train)\n",
                "baseline_metrics = calculate_all_metrics(y_train, y_train_pred, y_train_proba)\n",
                "\n",
                "print(f\"\\nðŸ“Š Baseline: Acc={baseline_metrics['accuracy']:.4f}, AUC={baseline_metrics['roc_auc']:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Drift Detection Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "drift_detector = DriftDetector()\n",
                "drift_detector.set_reference(\n",
                "    features=X_train,\n",
                "    predictions=y_train_proba,\n",
                "    feature_names=preprocessor.feature_columns,\n",
                "    skills_series=train_df.get('required_skills')\n",
                ")\n",
                "print(\"âœ“ Drift detector initialized\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Monthly Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "evaluator = MonthlyEvaluator()\n",
                "evaluator.set_baseline(baseline_metrics)\n",
                "\n",
                "historical_data = [('train', train_df)]\n",
                "\n",
                "print(f\"{'Month':<10} {'Samples':>8} {'Accuracy':>10} {'AUC':>10} {'ECE':>10}\")\n",
                "print(\"-\" * 50)\n",
                "\n",
                "for month_label, month_df in monthly_windows:\n",
                "    X_month, y_month = preprocessor.transform(month_df)\n",
                "    y_month_proba = model.predict_proba(X_month)\n",
                "    \n",
                "    metrics = evaluator.evaluate_month(model, X_month, y_month, month_label)\n",
                "    drift_detector.detect(X_month, y_month_proba, month_label, month_df.get('required_skills'))\n",
                "    \n",
                "    print(f\"{month_label:<10} {metrics['n_samples']:>8} {metrics['accuracy']:>10.3f} \"\n",
                "          f\"{metrics['roc_auc']:>10.3f} {metrics['calibration']['ece']:>10.3f}\")\n",
                "    \n",
                "    historical_data.append((month_label, month_df))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Performance Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trends = evaluator.get_trends()\n",
                "\n",
                "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
                "\n",
                "# Accuracy\n",
                "axes[0,0].plot(trends['months'], trends['accuracy'], 'o-', color='#2ecc71', lw=2)\n",
                "axes[0,0].axhline(baseline_metrics['accuracy'], color='red', ls='--', label=f'Baseline {baseline_metrics[\"accuracy\"]:.3f}')\n",
                "axes[0,0].set_title('Accuracy Over Time'); axes[0,0].legend(); axes[0,0].set_ylim(0,1)\n",
                "plt.setp(axes[0,0].xaxis.get_majorticklabels(), rotation=45)\n",
                "\n",
                "# AUC\n",
                "axes[0,1].plot(trends['months'], trends['roc_auc'], 's-', color='#3498db', lw=2)\n",
                "axes[0,1].axhline(baseline_metrics['roc_auc'], color='red', ls='--', label=f'Baseline {baseline_metrics[\"roc_auc\"]:.3f}')\n",
                "axes[0,1].set_title('ROC-AUC Over Time'); axes[0,1].legend(); axes[0,1].set_ylim(0,1)\n",
                "plt.setp(axes[0,1].xaxis.get_majorticklabels(), rotation=45)\n",
                "\n",
                "# ECE\n",
                "colors = ['#e74c3c' if e > 0.1 else '#2ecc71' for e in trends['ece']]\n",
                "axes[1,0].bar(trends['months'], trends['ece'], color=colors)\n",
                "axes[1,0].set_title('Calibration Error'); axes[1,0].axhline(0.1, color='orange', ls='--')\n",
                "plt.setp(axes[1,0].xaxis.get_majorticklabels(), rotation=45)\n",
                "\n",
                "# Entropy\n",
                "axes[1,1].plot(trends['months'], trends['mean_entropy'], 'D-', color='#9b59b6', lw=2)\n",
                "axes[1,1].set_title('Prediction Entropy')\n",
                "plt.setp(axes[1,1].xaxis.get_majorticklabels(), rotation=45)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(FIGURES_DIR / 'performance_dashboard.png', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "drift_summary = drift_detector.get_summary()\n",
                "\n",
                "print(\"=\"*60)\n",
                "print(\"EXPERIMENT SUMMARY\")\n",
                "print(\"=\"*60)\n",
                "print(f\"Training samples: {len(train_df)}\")\n",
                "print(f\"Deployment months: {len(monthly_windows)}\")\n",
                "print(f\"Features: {X_train.shape[1]}\")\n",
                "print(f\"\\nBaseline accuracy: {baseline_metrics['accuracy']:.3f}\")\n",
                "print(f\"Final month accuracy: {trends['accuracy'][-1]:.3f}\")\n",
                "print(f\"Performance drop: {baseline_metrics['accuracy'] - trends['accuracy'][-1]:.3f}\")\n",
                "print(f\"\\nDrift triggers: {drift_summary['triggered_periods']} / {drift_summary['total_periods']}\")\n",
                "print(f\"First failure: {evaluator.identify_failure_month()}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
